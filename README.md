# CLIP Implementation
Implementation of [Learning Transferable Visual Models From Natural Language Supervision](https://cdn.openai.com/papers/Learning_Transferable_Visual_Models_From_Natural_Language_Supervision.pdf)  

### DataSet

- Pre-Training
  - [Flicker30K](https://shannon.cs.illinois.edu/DenotationGraph/)  
  Only used 3rd label (31,783 points)

- Zero-shot
  - [Food101](https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/)